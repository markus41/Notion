# Blackboard Knowledge Base for Epic 2: .NET Orchestration Service
# Generated: 2025-10-08T10:15:00Z
# Pattern: Collaborative Knowledge Repository

architecture_patterns:
  - artifact_id: A-001
    category: "Workflow Orchestration"
    title: "Cosmos DB Optimistic Concurrency Pattern"
    description: "Use ETags for optimistic concurrency control in Cosmos DB to prevent lost updates during concurrent workflow state changes"
    implementation: |
      public async Task<WorkflowState> UpdateWorkflowStateAsync(WorkflowState state)
      {
          try
          {
              var requestOptions = new ItemRequestOptions
              {
                  IfMatchEtag = state.ETag // Use ETag for optimistic concurrency
              };

              var response = await _container.ReplaceItemAsync(
                  state,
                  state.Id,
                  new PartitionKey(state.WorkflowId),
                  requestOptions);

              return response.Resource;
          }
          catch (CosmosException ex) when (ex.StatusCode == HttpStatusCode.PreconditionFailed)
          {
              // ETag mismatch - another process updated the state
              _logger.LogWarning("Optimistic concurrency conflict for workflow {WorkflowId}", state.WorkflowId);

              // Reload current state and retry
              var currentState = await GetWorkflowStateAsync(state.WorkflowId);
              throw new ConcurrencyException("State was modified by another process", currentState);
          }
      }
    applicability:
      - StateManager implementation
      - Workflow state persistence
      - Checkpoint management
      - Concurrent task execution
    trade_offs:
      pros:
        - Prevents lost updates in distributed systems
        - Better performance than pessimistic locking
        - No deadlock risk
        - Works well with event sourcing
      cons:
        - Requires retry logic implementation
        - May need exponential backoff for high contention
        - Increased complexity in error handling

  - artifact_id: A-002
    category: "Workflow Orchestration"
    title: "Parallel Task Execution with Dependency Graph"
    description: "Execute independent workflow tasks in parallel while respecting dependency constraints using topological sorting"
    implementation: |
      public async Task ExecuteParallelWorkflowAsync(WorkflowDefinition workflow)
      {
          var dependencyGraph = BuildDependencyGraph(workflow.Tasks);
          var executionLayers = TopologicalSort(dependencyGraph);

          foreach (var layer in executionLayers)
          {
              // Tasks in same layer have no interdependencies - execute in parallel
              var parallelTasks = layer.Select(async task =>
              {
                  using var activity = Activity.StartActivity("ExecuteTask");
                  activity?.SetTag("task.id", task.Id);
                  activity?.SetTag("task.layer", layer.Index);

                  try
                  {
                      await _signalRHub.SendTaskStarted(workflow.Id, task.Id);

                      var result = await _pythonAgentClient.ExecuteTaskAsync(
                          task.AgentType,
                          task.Input,
                          workflow.Context);

                      await _stateManager.CreateCheckpointAsync(workflow.Id, task.Id, result);
                      await _signalRHub.SendTaskCompleted(workflow.Id, task.Id, result);

                      return result;
                  }
                  catch (Exception ex)
                  {
                      await _signalRHub.SendTaskFailed(workflow.Id, task.Id, ex.Message);
                      throw;
                  }
              });

              // Wait for all tasks in current layer before proceeding
              await Task.WhenAll(parallelTasks);
          }
      }
    applicability:
      - WorkflowExecutor parallel pattern
      - Complex workflow orchestration
      - CI/CD pipeline execution
      - Data processing pipelines
    trade_offs:
      pros:
        - Maximizes parallelization and resource utilization
        - Reduces overall execution time
        - Respects dependency constraints
        - Scalable to many concurrent tasks
      cons:
        - Complex error handling for partial failures
        - Resource contention at high parallelism
        - Debugging parallel execution is harder

  - artifact_id: A-003
    category: "Resilience"
    title: "Circuit Breaker with Polly for Agent Communication"
    description: "Implement circuit breaker pattern to prevent cascade failures when communicating with Python agents"
    implementation: |
      public class PythonAgentClient : IPythonAgentClient
      {
          private readonly IAsyncPolicy<HttpResponseMessage> _resiliencePolicy;

          public PythonAgentClient(HttpClient httpClient, ILogger<PythonAgentClient> logger)
          {
              _httpClient = httpClient;
              _logger = logger;

              // Combine multiple resilience strategies
              _resiliencePolicy = Policy.WrapAsync(
                  // Circuit breaker - open after 3 failures, stay open for 30 seconds
                  Policy.HandleResult<HttpResponseMessage>(r => !r.IsSuccessStatusCode)
                      .CircuitBreakerAsync(
                          handledEventsAllowedBeforeBreaking: 3,
                          durationOfBreak: TimeSpan.FromSeconds(30),
                          onBreak: (result, duration) =>
                          {
                              _logger.LogWarning("Circuit breaker opened for {Duration}s", duration.TotalSeconds);
                          },
                          onReset: () =>
                          {
                              _logger.LogInformation("Circuit breaker reset");
                          }),

                  // Retry with exponential backoff
                  Policy.HandleResult<HttpResponseMessage>(r => r.StatusCode >= HttpStatusCode.InternalServerError)
                      .WaitAndRetryAsync(
                          retryCount: 3,
                          sleepDurationProvider: retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),
                          onRetry: (outcome, timespan, retryCount, context) =>
                          {
                              _logger.LogWarning("Retry {RetryCount} after {Delay}s", retryCount, timespan.TotalSeconds);
                          }),

                  // Timeout per request
                  Policy.TimeoutAsync<HttpResponseMessage>(TimeSpan.FromSeconds(30))
              );
          }

          public async Task<AgentResponse> ExecuteTaskAsync(string agentType, object input, ExecutionContext context)
          {
              var response = await _resiliencePolicy.ExecuteAsync(async () =>
              {
                  var request = new AgentRequest
                  {
                      AgentType = agentType,
                      Input = input,
                      Context = context,
                      CorrelationId = Activity.Current?.Id ?? Guid.NewGuid().ToString()
                  };

                  return await _httpClient.PostAsJsonAsync($"api/agents/{agentType}/execute", request);
              });

              response.EnsureSuccessStatusCode();
              return await response.Content.ReadFromJsonAsync<AgentResponse>();
          }
      }
    applicability:
      - PythonAgentClient implementation
      - External service communication
      - Microservice interactions
      - Third-party API integration
    trade_offs:
      pros:
        - Prevents cascade failures
        - Automatic recovery from transient failures
        - Improves system resilience
        - Reduces unnecessary load on failing services
      cons:
        - Can mask underlying issues if not monitored
        - Adds latency during retry attempts
        - Requires careful tuning of thresholds

  - artifact_id: A-004
    category: "Real-time Communication"
    title: "SignalR Group-Based Workflow Broadcasting"
    description: "Use SignalR groups to efficiently broadcast workflow events to subscribed clients"
    implementation: |
      public class MetaAgentHub : Hub<IMetaAgentClient>
      {
          private readonly ILogger<MetaAgentHub> _logger;
          private readonly IConnectionManager _connectionManager;

          public async Task SubscribeToWorkflow(string workflowId)
          {
              var groupName = $"workflow-{workflowId}";

              // Add connection to workflow-specific group
              await Groups.AddToGroupAsync(Context.ConnectionId, groupName);

              // Track connection for monitoring
              await _connectionManager.AddConnectionAsync(Context.ConnectionId, workflowId);

              _logger.LogInformation("Client {ConnectionId} subscribed to workflow {WorkflowId}",
                  Context.ConnectionId, workflowId);

              // Send current workflow state to new subscriber
              var currentState = await _stateManager.GetWorkflowStateAsync(workflowId);
              await Clients.Caller.ReceiveWorkflowState(currentState);
          }

          public async Task UnsubscribeFromWorkflow(string workflowId)
          {
              var groupName = $"workflow-{workflowId}";

              await Groups.RemoveFromGroupAsync(Context.ConnectionId, groupName);
              await _connectionManager.RemoveConnectionAsync(Context.ConnectionId, workflowId);

              _logger.LogInformation("Client {ConnectionId} unsubscribed from workflow {WorkflowId}",
                  Context.ConnectionId, workflowId);
          }

          // Server-side method to broadcast to workflow subscribers
          public async Task BroadcastWorkflowEvent(string workflowId, WorkflowEvent evt)
          {
              var groupName = $"workflow-{workflowId}";

              await Clients.Group(groupName).ReceiveWorkflowEvent(evt);

              _logger.LogDebug("Broadcasted {EventType} to workflow {WorkflowId} subscribers",
                  evt.Type, workflowId);
          }

          public override async Task OnDisconnectedAsync(Exception? exception)
          {
              // Clean up connection tracking
              await _connectionManager.RemoveConnectionAsync(Context.ConnectionId);

              _logger.LogInformation("Client {ConnectionId} disconnected", Context.ConnectionId);

              await base.OnDisconnectedAsync(exception);
          }
      }
    applicability:
      - MetaAgentHub implementation
      - Real-time workflow monitoring
      - Live dashboard updates
      - Collaborative features
    trade_offs:
      pros:
        - Efficient group-based broadcasting
        - Automatic connection lifecycle management
        - Scales well with Azure SignalR Service
        - Built-in reconnection support
      cons:
        - Requires sticky sessions without Redis backplane
        - Additional infrastructure for scale-out
        - WebSocket connection limits per server

  - artifact_id: A-005
    category: "State Management"
    title: "Checkpoint-Based Recovery with Event Sourcing"
    description: "Implement checkpoint creation and recovery mechanism for workflow resumption after failures"
    implementation: |
      public class CheckpointManager : ICheckpointManager
      {
          private readonly CosmosContainer _checkpointContainer;
          private readonly CosmosContainer _eventContainer;

          public async Task<Checkpoint> CreateCheckpointAsync(
              string workflowId,
              string taskId,
              CheckpointType type,
              object state)
          {
              var checkpoint = new Checkpoint
              {
                  Id = Guid.NewGuid().ToString(),
                  WorkflowId = workflowId,
                  TaskId = taskId,
                  Type = type,
                  State = JsonSerializer.Serialize(state),
                  CreatedAt = DateTimeOffset.UtcNow,
                  TTL = (int)TimeSpan.FromDays(7).TotalSeconds // Auto-cleanup after 7 days
              };

              // Store checkpoint
              await _checkpointContainer.CreateItemAsync(
                  checkpoint,
                  new PartitionKey(workflowId));

              // Append checkpoint event to event stream
              var evt = new WorkflowEvent
              {
                  Id = Guid.NewGuid().ToString(),
                  WorkflowId = workflowId,
                  Type = "checkpoint.created",
                  Data = new { checkpointId = checkpoint.Id, taskId, type },
                  Timestamp = DateTimeOffset.UtcNow
              };

              await _eventContainer.CreateItemAsync(
                  evt,
                  new PartitionKey(workflowId));

              _logger.LogInformation("Created {Type} checkpoint for workflow {WorkflowId} at task {TaskId}",
                  type, workflowId, taskId);

              return checkpoint;
          }

          public async Task<WorkflowState> RecoverFromCheckpointAsync(
              string workflowId,
              string? checkpointId = null)
          {
              Checkpoint checkpoint;

              if (!string.IsNullOrEmpty(checkpointId))
              {
                  // Recover from specific checkpoint
                  checkpoint = await _checkpointContainer.ReadItemAsync<Checkpoint>(
                      checkpointId,
                      new PartitionKey(workflowId));
              }
              else
              {
                  // Find latest checkpoint
                  var query = new QueryDefinition(
                      "SELECT TOP 1 * FROM c WHERE c.workflowId = @workflowId ORDER BY c.createdAt DESC")
                      .WithParameter("@workflowId", workflowId);

                  var iterator = _checkpointContainer.GetItemQueryIterator<Checkpoint>(query);
                  var results = await iterator.ReadNextAsync();

                  checkpoint = results.FirstOrDefault()
                      ?? throw new InvalidOperationException($"No checkpoint found for workflow {workflowId}");
              }

              // Deserialize state
              var state = JsonSerializer.Deserialize<WorkflowState>(checkpoint.State)!;

              // Replay events after checkpoint to rebuild current state
              var eventQuery = new QueryDefinition(
                  "SELECT * FROM c WHERE c.workflowId = @workflowId AND c.timestamp > @checkpointTime ORDER BY c.timestamp")
                  .WithParameter("@workflowId", workflowId)
                  .WithParameter("@checkpointTime", checkpoint.CreatedAt);

              var eventIterator = _eventContainer.GetItemQueryIterator<WorkflowEvent>(eventQuery);

              while (eventIterator.HasMoreResults)
              {
                  var events = await eventIterator.ReadNextAsync();
                  foreach (var evt in events)
                  {
                      state = ApplyEvent(state, evt); // Event sourcing replay
                  }
              }

              _logger.LogInformation("Recovered workflow {WorkflowId} from checkpoint {CheckpointId}",
                  workflowId, checkpoint.Id);

              return state;
          }
      }
    applicability:
      - Workflow failure recovery
      - Long-running workflow suspension
      - State persistence for durability
      - Audit trail maintenance
    trade_offs:
      pros:
        - Enables workflow resumption after failures
        - Complete audit trail through event sourcing
        - Point-in-time recovery capability
        - Automatic cleanup with TTL
      cons:
        - Storage costs for checkpoints and events
        - Complexity of event replay logic
        - Potential consistency issues during replay

database_patterns:
  - artifact_id: D-001
    category: "Data Architecture"
    title: "Cosmos DB Partitioning Strategy for Workflows"
    description: "Optimize Cosmos DB partitioning for workflow state management to ensure scalability and performance"
    implementation: |
      public class WorkflowPartitioningStrategy
      {
          // Use WorkflowId as partition key for even distribution
          public string GetPartitionKey(WorkflowState state) => state.WorkflowId;

          // Container configuration
          public ContainerProperties ConfigureContainer()
          {
              return new ContainerProperties
              {
                  Id = "workflows",
                  PartitionKeyPath = "/workflowId",

                  // Indexing policy optimized for queries
                  IndexingPolicy = new IndexingPolicy
                  {
                      IndexingMode = IndexingMode.Consistent,
                      IncludedPaths = { new IncludedPath { Path = "/*" } },
                      ExcludedPaths =
                      {
                          new ExcludedPath { Path = "/state/*" }, // Don't index large state blob
                          new ExcludedPath { Path = "/_etag/?" }
                      },
                      CompositeIndexes = new Collection<Collection<CompositePath>>
                      {
                          new Collection<CompositePath>
                          {
                              new CompositePath { Path = "/status", Order = CompositePathSortOrder.Ascending },
                              new CompositePath { Path = "/createdAt", Order = CompositePathSortOrder.Descending }
                          }
                      }
                  },

                  // TTL for automatic cleanup
                  DefaultTimeToLive = (int)TimeSpan.FromDays(30).TotalSeconds
              };
          }
      }
    applicability:
      - Cosmos DB container design
      - StateManager implementation
      - Query optimization
    trade_offs:
      pros:
        - Even distribution across partitions
        - Optimized query performance
        - Automatic data cleanup
      cons:
        - Cross-partition queries for analytics
        - Fixed partitioning strategy

  - artifact_id: D-002
    category: "Data Architecture"
    title: "Connection Pooling for Cosmos DB Client"
    description: "Implement singleton Cosmos DB client with connection pooling for optimal performance"
    implementation: |
      public class CosmosDbService : ICosmosDbService
      {
          private static readonly CosmosClient _cosmosClient;
          private readonly Database _database;

          static CosmosDbService()
          {
              var options = new CosmosClientOptions
              {
                  ConnectionMode = ConnectionMode.Direct,
                  MaxRequestsPerTcpConnection = 16,
                  MaxTcpConnectionsPerEndpoint = 32,
                  PortReuseMode = PortReuseMode.PrivatePortPool,
                  IdleTcpConnectionTimeout = TimeSpan.FromMinutes(10),

                  // Retry configuration
                  MaxRetryAttemptsOnRateLimitedRequests = 9,
                  MaxRetryWaitTimeOnRateLimitedRequests = TimeSpan.FromSeconds(30),

                  // Performance optimization
                  AllowBulkExecution = true,

                  // Telemetry
                  ApplicationName = "AgentStudio",
                  EnableTcpConnectionEndpointRediscovery = true
              };

              _cosmosClient = new CosmosClient(
                  Environment.GetEnvironmentVariable("COSMOS_CONNECTION_STRING"),
                  options);
          }

          public Container GetContainer(string containerName)
          {
              return _database.GetContainer(containerName);
          }
      }
    applicability:
      - All Cosmos DB operations
      - Singleton service registration
      - Performance optimization
    trade_offs:
      pros:
        - Reuses TCP connections
        - Reduces latency
        - Better throughput
      cons:
        - Memory overhead for connection pool
        - Requires proper disposal

security_patterns:
  - artifact_id: S-001
    category: "Security"
    title: "Input Validation and Sanitization Pattern"
    description: "Comprehensive input validation for all API endpoints to prevent injection attacks"
    implementation: |
      public class WorkflowValidator : AbstractValidator<WorkflowRequest>
      {
          public WorkflowValidator()
          {
              RuleFor(x => x.WorkflowId)
                  .NotEmpty()
                  .Matches("^[a-zA-Z0-9-_]+$")
                  .Length(1, 100)
                  .WithMessage("WorkflowId must be alphanumeric with hyphens/underscores, 1-100 chars");

              RuleFor(x => x.Name)
                  .NotEmpty()
                  .MaximumLength(200)
                  .Must(NotContainScriptTags)
                  .WithMessage("Name must not contain script tags");

              RuleFor(x => x.Tasks)
                  .NotEmpty()
                  .Must(tasks => tasks.Count <= 100)
                  .WithMessage("Workflow cannot have more than 100 tasks");

              RuleForEach(x => x.Tasks).SetValidator(new TaskValidator());
          }

          private bool NotContainScriptTags(string input)
          {
              if (string.IsNullOrEmpty(input)) return true;

              var sanitized = HtmlEncoder.Default.Encode(input);
              return sanitized == input;
          }
      }

      // Apply globally via middleware
      public class ValidationMiddleware
      {
          public async Task InvokeAsync(HttpContext context, RequestDelegate next)
          {
              if (context.Request.Method == "POST" || context.Request.Method == "PUT")
              {
                  // Validate request body
                  context.Request.EnableBuffering();

                  // Size limit check
                  if (context.Request.ContentLength > 1_048_576) // 1MB limit
                  {
                      context.Response.StatusCode = 413;
                      await context.Response.WriteAsync("Request body too large");
                      return;
                  }
              }

              await next(context);
          }
      }
    applicability:
      - All API endpoints
      - User input processing
      - Data persistence operations
    trade_offs:
      pros:
        - Prevents injection attacks
        - Consistent validation across APIs
        - Clear error messages
      cons:
        - Additional processing overhead
        - Maintenance of validation rules

  - artifact_id: S-002
    category: "Security"
    title: "Secure Error Handling Pattern"
    description: "Handle errors securely without exposing sensitive information in responses or logs"
    implementation: |
      public class SecureExceptionMiddleware
      {
          private readonly RequestDelegate _next;
          private readonly ILogger<SecureExceptionMiddleware> _logger;

          public async Task InvokeAsync(HttpContext context)
          {
              try
              {
                  await _next(context);
              }
              catch (Exception ex)
              {
                  await HandleExceptionAsync(context, ex);
              }
          }

          private async Task HandleExceptionAsync(HttpContext context, Exception exception)
          {
              var correlationId = Activity.Current?.Id ?? Guid.NewGuid().ToString();

              // Log full exception internally with correlation ID
              _logger.LogError(exception,
                  "Unhandled exception occurred. CorrelationId: {CorrelationId}",
                  correlationId);

              context.Response.StatusCode = exception switch
              {
                  ValidationException => StatusCodes.Status400BadRequest,
                  UnauthorizedException => StatusCodes.Status401Unauthorized,
                  ForbiddenException => StatusCodes.Status403Forbidden,
                  NotFoundException => StatusCodes.Status404NotFound,
                  ConcurrencyException => StatusCodes.Status409Conflict,
                  _ => StatusCodes.Status500InternalServerError
              };

              // Return safe error response - no sensitive details
              var response = new ErrorResponse
              {
                  Error = exception switch
                  {
                      ValidationException ve => ve.Message, // Safe - contains validation details
                      NotFoundException => "Resource not found",
                      UnauthorizedException => "Authentication required",
                      ForbiddenException => "Access denied",
                      ConcurrencyException => "Resource was modified by another process",
                      _ => "An error occurred processing your request"
                  },
                  CorrelationId = correlationId,
                  Timestamp = DateTimeOffset.UtcNow
              };

              await context.Response.WriteAsJsonAsync(response);
          }
      }
    applicability:
      - Global exception handling
      - API error responses
      - Security-sensitive operations
    trade_offs:
      pros:
        - No sensitive data leakage
        - Consistent error format
        - Correlation for debugging
      cons:
        - Less detailed errors for consumers
        - Requires log access for debugging

performance_patterns:
  - artifact_id: P-001
    category: "Performance"
    title: "Async/Await Optimization with ConfigureAwait"
    description: "Optimize async operations to avoid unnecessary context switching"
    implementation: |
      public class WorkflowExecutor : IWorkflowExecutor
      {
          // Use ConfigureAwait(false) in library code to avoid context capture
          public async Task<ExecutionResult> ExecuteAsync(WorkflowDefinition workflow)
          {
              // Start multiple operations concurrently
              var stateTask = _stateManager.GetStateAsync(workflow.Id).ConfigureAwait(false);
              var configTask = _configService.GetConfigAsync().ConfigureAwait(false);

              // Await both - more efficient than sequential awaits
              await Task.WhenAll(stateTask, configTask).ConfigureAwait(false);

              var state = await stateTask;
              var config = await configTask;

              // Use ValueTask for hot path operations
              await ProcessWorkflowAsync(workflow, state, config).ConfigureAwait(false);

              // Batch operations where possible
              var updates = new List<Task>();
              foreach (var task in workflow.Tasks)
              {
                  updates.Add(UpdateTaskAsync(task).ConfigureAwait(false));
              }

              await Task.WhenAll(updates).ConfigureAwait(false);

              return new ExecutionResult { Success = true };
          }

          // Use ValueTask for frequently called operations that might complete synchronously
          public async ValueTask<bool> IsTaskReadyAsync(string taskId)
          {
              // Check in-memory cache first
              if (_cache.TryGetValue(taskId, out var cachedResult))
              {
                  return cachedResult; // Completes synchronously - no allocation
              }

              // Fall back to async database check
              var result = await _database.CheckTaskReadyAsync(taskId).ConfigureAwait(false);
              _cache.Set(taskId, result, TimeSpan.FromMinutes(1));

              return result;
          }
      }
    applicability:
      - All async operations
      - Library code
      - Performance-critical paths
    trade_offs:
      pros:
        - Reduces context switching overhead
        - Better thread pool utilization
        - Lower memory allocations
      cons:
        - Loss of synchronization context
        - Careful consideration needed in ASP.NET

  - artifact_id: P-002
    category: "Performance"
    title: "Redis Caching Strategy with Cache-Aside Pattern"
    description: "Implement distributed caching with Redis to reduce database load"
    implementation: |
      public class CachedStateManager : IStateManager
      {
          private readonly IDistributedCache _cache;
          private readonly IStateManager _innerManager;

          public async Task<WorkflowState> GetStateAsync(string workflowId)
          {
              var cacheKey = $"workflow:state:{workflowId}";

              // Try cache first
              var cached = await _cache.GetStringAsync(cacheKey);
              if (!string.IsNullOrEmpty(cached))
              {
                  _logger.LogDebug("Cache hit for workflow {WorkflowId}", workflowId);
                  return JsonSerializer.Deserialize<WorkflowState>(cached)!;
              }

              // Cache miss - load from database
              var state = await _innerManager.GetStateAsync(workflowId);

              // Cache with sliding expiration
              var cacheOptions = new DistributedCacheEntryOptions
              {
                  SlidingExpiration = TimeSpan.FromMinutes(5),
                  AbsoluteExpirationRelativeToNow = TimeSpan.FromHours(1)
              };

              await _cache.SetStringAsync(
                  cacheKey,
                  JsonSerializer.Serialize(state),
                  cacheOptions);

              return state;
          }

          public async Task UpdateStateAsync(WorkflowState state)
          {
              // Update database
              await _innerManager.UpdateStateAsync(state);

              // Invalidate cache
              var cacheKey = $"workflow:state:{state.WorkflowId}";
              await _cache.RemoveAsync(cacheKey);

              // Optionally pre-populate cache with new value
              var cacheOptions = new DistributedCacheEntryOptions
              {
                  SlidingExpiration = TimeSpan.FromMinutes(5)
              };

              await _cache.SetStringAsync(
                  cacheKey,
                  JsonSerializer.Serialize(state),
                  cacheOptions);
          }
      }
    applicability:
      - Frequently accessed data
      - Read-heavy workloads
      - Session state management
    trade_offs:
      pros:
        - Reduces database load
        - Improves response times
        - Scales horizontally
      cons:
        - Cache invalidation complexity
        - Additional infrastructure
        - Potential stale data

event_log:
  - timestamp: "2025-10-08T10:15:00Z"
    event_type: "knowledge.contributed"
    data:
      contributor: "orchestrator"
      artifacts_count: 12
      categories: ["architecture", "database", "security", "performance"]

  - timestamp: "2025-10-08T10:15:30Z"
    event_type: "blackboard.initialized"
    data:
      total_artifacts: 12
      ready_for_execution: true